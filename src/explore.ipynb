{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Download our content for model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "url = 'https://storage.googleapis.com/datascience-materials/dogs-vs-cats.zip'\n",
                "\n",
                "import requests\n",
                "import zipfile\n",
                "from io import BytesIO\n",
                "\n",
                "extract_to_directory = \"extracted_content\" # Directory to extract files into\n",
                "\n",
                "# Send GET request and wrap content in BytesIO\n",
                "response = requests.get(url)\n",
                "with zipfile.ZipFile(BytesIO(response.content)) as zfile:\n",
                "    # Extract all files to a specified directory\n",
                "    zfile.extractall(extract_to_directory)\n",
                "\n",
                "print(f\"Content extracted to '{extract_to_directory}' successfully.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#!pip install tensorflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow import keras"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 20000 files belonging to 2 classes.\n",
                        "Found 2500 files belonging to 2 classes.\n",
                        "Found 2500 files belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "# make train, test, and validation sets\n",
                "img_size = (224,224)\n",
                "batch_size = 32\n",
                "\n",
                "\n",
                "train_ds = keras.utils.image_dataset_from_directory(\n",
                "    \"extracted_content/dogs-vs-cats/train/\",\n",
                "    image_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    label_mode=\"binary\",\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "val_ds = keras.utils.image_dataset_from_directory(\n",
                "    \"extracted_content/dogs-vs-cats/val/\",\n",
                "    image_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    label_mode=\"binary\",\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "test_ds = keras.utils.image_dataset_from_directory(\n",
                "    \"extracted_content/dogs-vs-cats/test/\",\n",
                "    image_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    label_mode=\"binary\",\n",
                "    shuffle=True,\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.applications import VGG16\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Flatten, Dense #Load pre-trained model\n",
                "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
                "base_model.trainable = False  # Freeze weights\n",
                "\n",
                "# Add new layers\n",
                "model = Sequential([\n",
                "        base_model,\n",
                "        Flatten(),\n",
                "        Dense(128, activation='relu'),\n",
                "        Dense(1, activation='sigmoid')  # Binary classification\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Due to computational constraints, a representative subset of the training data was used for optimization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.losses import BinaryCrossentropy\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 255.0\n"
                    ]
                }
            ],
            "source": [
                "# Expecting 0.0 - 255.0 min/max format\n",
                "for x, y in train_ds.take(1):\n",
                "    print(tf.reduce_min(x).numpy(), tf.reduce_max(x).numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "TRAIN_STEPS = 200\n",
                "VAL_STEPS = 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Build our model checkpoints and early stopping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "checkpoint = ModelCheckpoint(\n",
                "    filepath=\"best_vgg16_model.keras\",\n",
                "    monitor=\"val_loss\",\n",
                "    save_best_only=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "early_stop = EarlyStopping(\n",
                "    monitor=\"val_loss\",\n",
                "    patience=2,\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compile our sequential model for loss of Binary Cross Entropy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(optimizer=\"adam\", loss = BinaryCrossentropy(from_logits=False), metrics= [\"accuracy\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fit model on our params, including callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/10\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8273 - loss: 6.8858\n",
                        "Epoch 1: val_loss improved from None to 0.12685, saving model to best_vgg16_model.keras\n",
                        "\n",
                        "Epoch 1: finished saving model to best_vgg16_model.keras\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 4s/step - accuracy: 0.9159 - loss: 1.5772 - val_accuracy: 0.9613 - val_loss: 0.1268\n",
                        "Epoch 2/10\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9733 - loss: 0.0848\n",
                        "Epoch 2: val_loss did not improve from 0.12685\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 4s/step - accuracy: 0.9800 - loss: 0.0615 - val_accuracy: 0.9688 - val_loss: 0.1371\n",
                        "Epoch 3/10\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9908 - loss: 0.0284\n",
                        "Epoch 3: val_loss improved from 0.12685 to 0.12134, saving model to best_vgg16_model.keras\n",
                        "\n",
                        "Epoch 3: finished saving model to best_vgg16_model.keras\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 4s/step - accuracy: 0.9928 - loss: 0.0196 - val_accuracy: 0.9694 - val_loss: 0.1213\n",
                        "Epoch 4/10\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9954 - loss: 0.0111\n",
                        "Epoch 4: val_loss did not improve from 0.12134\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 4s/step - accuracy: 0.9959 - loss: 0.0100 - val_accuracy: 0.9631 - val_loss: 0.1619\n",
                        "Epoch 5/10\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - accuracy: 0.9987 - loss: 0.0061 \n",
                        "Epoch 5: val_loss did not improve from 0.12134\n",
                        "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6843s\u001b[0m 34s/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9694 - val_loss: 0.1335\n",
                        "Epoch 5: early stopping\n",
                        "Restoring model weights from the end of the best epoch: 3.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<keras.src.callbacks.history.History at 0x2902900ce90>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.fit(\n",
                "    train_ds.take(TRAIN_STEPS),\n",
                "    epochs=10,\n",
                "    validation_data=val_ds.take(VAL_STEPS),\n",
                "    callbacks=[checkpoint, early_stop]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.models import load_model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Load our best model from our training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_model = load_model(\"best_vgg16_model.keras\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Make predictions on our test dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred_probs = best_model.predict(test_ds)\n",
                "y_pred = (y_pred_probs > 0.5).astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(y_pred_probs.shape)\n",
                "print(y_pred.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "y_true = np.concatenate([\n",
                "    y for x, y in test_ds\n",
                "]).astype(int)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_true = y_true.flatten()\n",
                "y_pred = y_pred.flatten()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "print(cm)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Despite preprocessing and optimization using EarlyStopping and ModelCheckpoint, the frozen VGG16 backbone with limited training iterations produced near-random performance. This outcome highlights the computational trade-offs inherent in transfer learning and demonstrates that model capacity and fine-tuning are critical when adapting large pre-trained networks under constrained resources."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
